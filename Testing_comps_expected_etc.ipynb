{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# exploring allele1/2 data interactively\n",
    "\n",
    "carefully defining compartments, expected, and looking at the allele1/2 interaction profile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### make notebook feel like sublime\n",
    "stollen from the great and mighty internets\n",
    "multiline editing and some nice key-bindings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "require([\"codemirror/keymap/sublime\", \"notebook/js/cell\", \"base/js/namespace\"],\n",
       "    function(sublime_keymap, cell, IPython) {\n",
       "    \n",
       "        cell.Cell.options_default.cm_config.keyMap = 'sublime';\n",
       "    \n",
       "        var cells = IPython.notebook.get_cells();\n",
       "    \n",
       "    \n",
       "        for(var cl=0; cl< cells.length ; cl++){\n",
       "            cells[cl].code_mirror.setOption('keyMap', 'sublime');\n",
       "        }\n",
       "    }\n",
       ");\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%javascript\n",
    "require([\"codemirror/keymap/sublime\", \"notebook/js/cell\", \"base/js/namespace\"],\n",
    "    function(sublime_keymap, cell, IPython) {\n",
    "    \n",
    "        cell.Cell.options_default.cm_config.keyMap = 'sublime';\n",
    "    \n",
    "        var cells = IPython.notebook.get_cells();\n",
    "    \n",
    "    \n",
    "        for(var cl=0; cl< cells.length ; cl++){\n",
    "            cells[cl].code_mirror.setOption('keyMap', 'sublime');\n",
    "        }\n",
    "    }\n",
    ");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# i had to install this beauty https://github.com/matplotlib/ipympl\n",
    "# to make following to work ...\n",
    "%matplotlib widget\n",
    "import ipywidgets as widgets\n",
    "\n",
    "# %matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "\n",
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cooler\n",
    "\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bioframe\n",
    "from bioframe.io import resources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # make pandas display entire dataframes\n",
    "# pd.set_option(\"display.max_rows\", None, \"display.max_columns\", None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cooltools used dekkerlab-fork, develop-branch, commit-af508bba9c6577b8271b716ba27c330bead15981\n",
    "\n",
    "from cooler.tools import split, partition\n",
    "from functools import partial\n",
    "from cooltools import expected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cooltools import numutils\n",
    "from cooltools.eigdecomp import cooler_cis_eig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from helper_module import fillcolor_compartment_style, to_uscs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "cooler_names = [#'all-allele-spe.galGal5.mapq_30.1000.mcool',\n",
    "#'all-allele-spe-high-cis.galGal5.mapq_30.1000.mcool',\n",
    "    'all-allele-spe-2percent-highcis.galGal5.mapq_30.1000.mcool',\n",
    "    'all-allele-spe-1percent-highcis.galGal5.mapq_30.1000.mcool',\n",
    "'MNP-DT40-1-3-16-2p-R1-T1__galGal5.galGal5.mapq_30.1000.mcool',\n",
    "'MNP-DT40-1-3-16-R1-T1__galGal5.galGal5.mapq_30.1000.mcool',\n",
    "'MNP-DT40-1-3-16-R2-T1__galGal5.galGal5.mapq_30.1000.mcool',\n",
    "'MNP-DT40-1-3-17-2p-R1-T1__galGal5.galGal5.mapq_30.1000.mcool',\n",
    "'MNP-DT40-1-3-17-R1-T1__galGal5.galGal5.mapq_30.1000.mcool',\n",
    "'MNP-DT40-1-3-3-R1-T1__galGal5.galGal5.mapq_30.1000.mcool',\n",
    "'MNP-DT40-WT1-R1-T1__galGal5.galGal5.mapq_30.1000.mcool',\n",
    "'MNP-DT40-WT2-R1-T1__galGal5.galGal5.mapq_30.1000.mcool']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### generate some nicer sample names from coolers ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sample</th>\n",
       "      <th>mcool</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>pool-2percent-highcis</td>\n",
       "      <td>all-allele-spe-2percent-highcis.galGal5.mapq_3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>pool-1percent-highcis</td>\n",
       "      <td>all-allele-spe-1percent-highcis.galGal5.mapq_3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>clone-16-2p</td>\n",
       "      <td>MNP-DT40-1-3-16-2p-R1-T1__galGal5.galGal5.mapq...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>clone-16</td>\n",
       "      <td>MNP-DT40-1-3-16-R1-T1__galGal5.galGal5.mapq_30...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>clone-16-R2</td>\n",
       "      <td>MNP-DT40-1-3-16-R2-T1__galGal5.galGal5.mapq_30...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>clone-17-2p</td>\n",
       "      <td>MNP-DT40-1-3-17-2p-R1-T1__galGal5.galGal5.mapq...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>clone-17</td>\n",
       "      <td>MNP-DT40-1-3-17-R1-T1__galGal5.galGal5.mapq_30...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>clone-3</td>\n",
       "      <td>MNP-DT40-1-3-3-R1-T1__galGal5.galGal5.mapq_30....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>WT1</td>\n",
       "      <td>MNP-DT40-WT1-R1-T1__galGal5.galGal5.mapq_30.10...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>WT2</td>\n",
       "      <td>MNP-DT40-WT2-R1-T1__galGal5.galGal5.mapq_30.10...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  sample                                              mcool\n",
       "0  pool-2percent-highcis  all-allele-spe-2percent-highcis.galGal5.mapq_3...\n",
       "1  pool-1percent-highcis  all-allele-spe-1percent-highcis.galGal5.mapq_3...\n",
       "2            clone-16-2p  MNP-DT40-1-3-16-2p-R1-T1__galGal5.galGal5.mapq...\n",
       "3               clone-16  MNP-DT40-1-3-16-R1-T1__galGal5.galGal5.mapq_30...\n",
       "4            clone-16-R2  MNP-DT40-1-3-16-R2-T1__galGal5.galGal5.mapq_30...\n",
       "5            clone-17-2p  MNP-DT40-1-3-17-2p-R1-T1__galGal5.galGal5.mapq...\n",
       "6               clone-17  MNP-DT40-1-3-17-R1-T1__galGal5.galGal5.mapq_30...\n",
       "7                clone-3  MNP-DT40-1-3-3-R1-T1__galGal5.galGal5.mapq_30....\n",
       "8                    WT1  MNP-DT40-WT1-R1-T1__galGal5.galGal5.mapq_30.10...\n",
       "9                    WT2  MNP-DT40-WT2-R1-T1__galGal5.galGal5.mapq_30.10..."
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# multiqc learnings here, btw!...\n",
    "renamings = {\"all-allele-spe\":\"pool\",\n",
    "            \".galGal5.mapq_30.1000.mcool\":\"\",\n",
    "            \"MNP-DT40-\":\"\",\n",
    "            \"-T1__galGal5\":\"\",\n",
    "            \"-R1\":\"\",\n",
    "            \"1-3-\":\"clone-\"}\n",
    "\n",
    "sample_names = []\n",
    "for c in cooler_names:\n",
    "    for rf,rt in renamings.items():\n",
    "        c = re.sub(rf,rt,c)\n",
    "    sample_names.append(c)\n",
    "\n",
    "# sample_names\n",
    "\n",
    "# form a df of samples here:\n",
    "samples = pd.DataFrame({\"sample\":sample_names,\"mcool\":cooler_names})\n",
    "\n",
    "samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bar_signal(oe,signal,thresh=0.1):\n",
    "    oe1 = np.nanmean(oe[signal >= thresh])\n",
    "    oe2 = np.nanmean(oe[(signal >= -thresh)&(signal < thresh)])\n",
    "    oe3 = np.nanmean(oe[signal < -thresh])\n",
    "    return [oe1,oe2,oe3]\n",
    "\n",
    "#     #     [a1A,a2A,a1B,a2B]\n",
    "#     # ...\n",
    "#     a1A = np.nanmean(oe1_vis[cmpp >= 0.1])\n",
    "#     a1AB = np.nanmean(oe1_vis[(cmpp >= -0.1)&(cmpp < 0.1)])\n",
    "#     a1B = np.nanmean(oe1_vis[cmpp < -0.1])\n",
    "\n",
    "#     a2A = np.nanmean(oe2_vis[cmpp >= 0.1])\n",
    "#     a2AB = np.nanmean(oe2_vis[(cmpp >= -0.1)&(cmpp < 0.1)])\n",
    "#     a2B = np.nanmean(oe2_vis[cmpp < -0.1])\n",
    "\n",
    "#     axbar.bar(range(6),[a1A,a1AB,a1B,a2A,a2AB,a2B],color=list('rrrggg'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# READ SOME COMPARTMENTS IN ...\n",
    "# we have only 100kb externally called compartments ...\n",
    "binsize = 100_000\n",
    "res_human = f\"{int(binsize/1000)}kb\"\n",
    "\n",
    "comp_path = \"/home/venevs/DOTS_TESTING/alv-chicken/MNP/analysis/compartment\"\n",
    "comp_name = f\"poolMNP-bettercis.{res_human}.eigs.cis.vecs.txt\"\n",
    "\n",
    "cmp_vals50kb = None\n",
    "\n",
    "cmp = pd.read_csv(os.path.join(comp_path,comp_name),sep='\\t')\n",
    "\n",
    "chrom=\"chr1\"\n",
    "# get chromosomal compartments and interpolated version of those ...\n",
    "cmp_vals = cmp[cmp[\"chrom\"]==chrom]['E1'].values\n",
    "# # interpolated_cmp = get_proper_interpolated_compartments(clr, cmp_vals, chrom)\n",
    "# cmp_vals = cmp_vals[::10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# READ SOME COOLERS ...\n",
    "binsize = 1_000_000\n",
    "res_human = f\"{int(binsize/1000)}kb\"\n",
    "\n",
    "# refres compartments derived earlier ...\n",
    "# get chromosomal compartments and interpolated version of those ...\n",
    "cmp_vals = cmp[cmp[\"chrom\"]==chrom]['E1'].values\n",
    "\n",
    "\n",
    "# oldref-20200617\n",
    "# cool_path = \"/home/venevs/DOTS_TESTING/alv-chicken/oldref-20200410\"\n",
    "cool_path = \"/home/venevs/DOTS_TESTING/alv-chicken/oldref-20200617\"\n",
    "get_cpath = lambda c: os.path.join(cool_path,c+f\"::/resolutions/{binsize}\")\n",
    "\n",
    "samples[\"cool\"] = [cooler.Cooler(get_cpath(c)) for c in samples[\"mcool\"]]\n",
    "\n",
    "\n",
    "samples[\"sum\"] = [s.info[\"sum\"] for s in samples[\"cool\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a bunch of decisions/assignments, based on the binsize of the cooler:\n",
    "\n",
    "if binsize == 50_000:\n",
    "    cmp_vals_tmp = np.zeros(2*len(cmp_vals))\n",
    "    cmp_vals_tmp[0::2] = cmp_vals\n",
    "    cmp_vals_tmp[1::2] = cmp_vals\n",
    "    cmp_vals = cmp_vals_tmp\n",
    "    bad_bins =  np.r_[np.arange(180,189),np.arange(650,655),np.arange(1440,1446)]\n",
    "elif binsize == 100_000:\n",
    "    bad_bins =  np.r_[np.arange(90,95),np.arange(325,330),np.arange(720,723)]\n",
    "    cmp_vals = cmp_vals\n",
    "elif binsize == 250_000:\n",
    "    bad_bins =  np.array([9*4,9*4+1,32*4,32*4+1,72*4,72*4+1])\n",
    "    if cmp_vals50kb is None:\n",
    "        cmp_vals = cmp_vals[::3] # probably wrong ...\n",
    "    else:\n",
    "        cmp_vals = cmp_vals50kb[::5].copy()\n",
    "elif binsize == 500_000:\n",
    "    bad_bins =  np.array([9*2,9*2+1,32*2,32*2+1,72*2,72*2+1])\n",
    "    cmp_vals = cmp_vals[::5]\n",
    "elif binsize == 1_000_000:\n",
    "    bad_bins =  np.array([9,32,72])\n",
    "    cmp_vals = cmp_vals[::10]\n",
    "else:\n",
    "    print(\"uh oh - dunno !\")\n",
    "#  \n",
    "# insertion site, bin-id:    \n",
    "#\n",
    "\n",
    "if binsize == 50_000:\n",
    "    ins_row = 1451 # obvious only in raw data, balaned has al1 and al2 separated !\n",
    "elif binsize == 100_000:\n",
    "    ins_row = 725 # 290*2.5\n",
    "elif binsize == 250_000:\n",
    "    ins_row = 290 # ok\n",
    "elif binsize == 500_000:\n",
    "    ins_row = 145\n",
    "elif binsize == 1_000_000:\n",
    "    ins_row = 72\n",
    "else:\n",
    "    print(\"uh oh - dunno where is the insertion!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "clr, = samples[\"cool\"][samples[\"sample\"] == \"pool-2percent-highcis\"].values\n",
    "\n",
    "parm = (\"chr1\",0,74626886)\n",
    "qarm = (\"chr1\",75126886,196202544)\n",
    "centro = (\"chr1\",74626886,75126886)\n",
    "balance = True\n",
    "\n",
    "# bad_bins = None\n",
    "ignore_diags = 2\n",
    "theregion=parm\n",
    "theregion_name=\"parm\"\n",
    "\n",
    "bad_bin_region = (\"chr1\",9000000,9500000)\n",
    "\n",
    "weight_name = \"weight\"\n",
    "weight1 = weight_name + \"1\"\n",
    "weight2 = weight_name + \"2\"\n",
    "transforms = {\"balanced\": lambda p: p[\"count\"] * p[weight1] * p[weight2]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load replication timing in here !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bioframe import io\n",
    "\n",
    "timfname = \"/home/venevs/DOTS_TESTING/alv-chicken/timing_wt.bed\"\n",
    "\n",
    "bins = clr.bins().fetch(chrom).copy()\n",
    "\n",
    "val_rt = io.read_table(timfname,\n",
    "                       schema=bioframe.schemas.BEDGRAPH_FIELDS,\n",
    "                       skiprows=1)\n",
    "val_rt = val_rt.rename({0:\"chrom\",1:\"start\",2:\"end\",3:\"rt\"},\n",
    "                       axis=1)\n",
    "\n",
    "# fnd = plt.figure(figsize=(10,2))\n",
    "# val_rt.plot(x=1,y=3,ax=plt.gca(),lw=1)\n",
    "\n",
    "# overlap RT signal with our bins ...\n",
    "binned_rt = bioframe.ops.overlap(bins, val_rt, suffixes=['', '_rt'])\n",
    "# freaking pd.NA !? can't cast them to float ... why ? why are they there in the first place ?!\n",
    "binned_rt[\"value_rt\"] = binned_rt[\"value_rt\"].apply(lambda x: np.nan if x is pd.NA else x)\n",
    "\n",
    "binned_rt = binned_rt \\\n",
    "                .drop(labels=[\"chrom_rt\",\"start_rt\",\"end_rt\"],axis=1) \\\n",
    "                .astype({\"start\":int,\"end\":int,\"weight\":float})\n",
    "\n",
    "# finally :\n",
    "binned_rt = binned_rt.groupby([\"chrom\",\"start\",\"end\"],observed=True,sort=False).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### compute compartments per arm masking bad bins ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "51dd690cb38f468baaea0a62b6d1abf4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1040\n"
     ]
    }
   ],
   "source": [
    "# from cooltools import eigdecomp\n",
    "# pcmp = cmp_vals[slice(*clr.extent(parm))]\n",
    "# qcmp = cmp_vals[slice(*clr.extent(qarm))]\n",
    "# phasing_trck = np.concatenate((pcmp,qcmp))\n",
    "\n",
    "# insert existing eigen track as a phasing track:\n",
    "bins = clr.bins()[:].copy()\n",
    "# no support for bad bins in eigdecomp ...\n",
    "cmp_phase = np.zeros(len(bins))\n",
    "cmp_phase[:len(cmp_vals)] = cmp_vals\n",
    "bins.insert(4,\"cmp\",cmp_phase)\n",
    "\n",
    "eigvals1, eigvec_table1 = cooler_cis_eig(\n",
    "    clr=clr,\n",
    "    bins=bins,\n",
    "    regions= [parm, qarm],\n",
    "    n_eigs=2,\n",
    "    bad_bins = bad_bins,\n",
    "    phasing_track_col=\"cmp\",\n",
    "    clip_percentile=99.9,\n",
    "    sort_metric=None,\n",
    ")\n",
    "\n",
    "# plot it, just in case:\n",
    "f = plt.figure(figsize=(10,3))\n",
    "ax = f.add_subplot(2,1,1)\n",
    "axrt = f.add_subplot(2,1,2)\n",
    "print(len(eigvec_table1))\n",
    "fillcolor_compartment_style(eigvec_table1[\"E1\"], ax)\n",
    "# fillcolor_compartment_style(cmp_vals, ax)\n",
    "for bb in bad_bins:\n",
    "    ax.axvline(bb)\n",
    "\n",
    "fillcolor_compartment_style(binned_rt[\"value_rt\"], axrt)\n",
    "\n",
    "    \n",
    "# redefine cmp_vals:\n",
    "cmp_vals = eigvec_table1[eigvec_table1[\"chrom\"]==chrom][\"E1\"].values\n",
    "\n",
    "if binsize == 50_000:\n",
    "    cmp_vals50kb = cmp_vals.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### correlate RT and EV1 to check if apparent shift is real"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f28be023a294c5ba96e61aec70d4370",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0226e59d200144cfbea74dd31ae04510",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=0, description='shhh', max=30), Output()), _dom_classes=('widget-interac…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ftftrf = plt.figure(figsize=(3,3))\n",
    "\n",
    "x = eigvec_table1[\"E1\"].iloc[slice(*clr.extent(chrom))].values\n",
    "y = binned_rt[\"value_rt\"].values\n",
    "\n",
    "ax = plt.gca()\n",
    "\n",
    "@widgets.interact(shhh=(0,30))\n",
    "def update(shhh=0):\n",
    "    ax.clear()\n",
    "    \n",
    "    if shhh == 0:\n",
    "        xv = x[:].copy()\n",
    "        yv = y[:].copy()\n",
    "    else:\n",
    "        xv = x[shhh:].copy()\n",
    "        yv = y[:-shhh].copy()\n",
    "    rrr = pd.DataFrame({\"x\":xv,\"y\":yv}).corr().loc[\"x\",\"y\"]\n",
    "    #     ax.hexbin(xv,yv,alpha=0.3,label=f\"{rrr}\")\n",
    "    ax.hexbin(xv,yv,gridsize=(30,18) ,cmap=\"YlOrBr\")\n",
    "    ax.set_title(f\"{rrr}\")\n",
    "    #     plt.legend()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd2fef1a7c334490889568ec18bdc83e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot it, just in case:\n",
    "fаа = plt.figure(figsize=(4,4))\n",
    "# ax = f.add_subplot()\n",
    "# print(len(eigvec_table1))\n",
    "# fillcolor_compartment_style(eigvec_table1[\"E1\"], ax)\n",
    "# fillcolor_compartment_style(cmp_vals, ax)\n",
    "# for bb in bad_bins:\n",
    "#     ax.axvline(bb)\n",
    "\n",
    "cmap = matplotlib.cm.YlOrBr\n",
    "cmap.set_bad('grey',.5)\n",
    "mat = clr.matrix(balance=False).fetch(parm)\n",
    "img = plt.imshow(np.log(mat),cmap=\"YlOrBr\",interpolation='nearest')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### calculate expecteds the new way ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocess as mp\n",
    "\n",
    "nproc = 4\n",
    "\n",
    "# matching regions: p-arm        pq-inter arm      q-arm            chr1-wide ...\n",
    "left_regions  = [(*parm,'parm'),(*parm,'parm'),(*qarm,'qarm'),(\"chr1\",0,clr.chromsizes[\"chr1\"],\"chr1\")]\n",
    "right_regions = [(*parm,'parm'),(*qarm,'qarm'),(*qarm,'qarm'),(\"chr1\",0,clr.chromsizes[\"chr1\"],\"chr1\")]\n",
    "# execution details\n",
    "if nproc > 1:\n",
    "    pool = mp.Pool(nproc)\n",
    "    map_ = pool.map\n",
    "else:\n",
    "    map_ = map\n",
    "\n",
    "exp_df_bad = expected.diagsum_asymm(clr,\n",
    "                 regions1 = left_regions,\n",
    "                 regions2 = right_regions,\n",
    "                 transforms=transforms,\n",
    "                 weight_name='weight',\n",
    "                 bad_bins=bad_bins,\n",
    "                 map = map_)\n",
    "exp_df_bad[\"balanced.avg\"] = exp_df_bad[\"balanced.sum\"]/exp_df_bad[\"n_valid\"]\n",
    "exp_grp_bad = exp_df_bad.groupby([\"region1\",\"region2\"])\n",
    "# extract several expecteds for different regions ...\n",
    "parm_exp_bad = exp_grp_bad.get_group((\"parm\",\"parm\"))\n",
    "pqarm_exp_bad = exp_grp_bad.get_group((\"parm\",\"qarm\"))\n",
    "# qarm_exp_bad = exp_grp_bad.get_group((\"qarm\",\"qarm\"))\n",
    "chr1_exp_bad = exp_grp_bad.get_group((\"chr1\",\"chr1\"))\n",
    "\n",
    "\n",
    "exp_df_bad_raw = expected.diagsum_asymm(clr,\n",
    "                     regions1 = left_regions,\n",
    "                     regions2 = right_regions,\n",
    "                     transforms={},\n",
    "                     weight_name=None,\n",
    "                     bad_bins=bad_bins,\n",
    "                     map = map_)\n",
    "exp_df_bad_raw[\"count.avg\"] = exp_df_bad_raw[\"count.sum\"]/exp_df_bad_raw[\"n_valid\"]\n",
    "exp_df_bad_raw_grp = exp_df_bad_raw.groupby([\"region1\",\"region2\"])\n",
    "# extract several expecteds for different regions ...\n",
    "parm_exp_bad_raw = exp_df_bad_raw_grp.get_group((\"parm\",\"parm\"))\n",
    "pqarm_exp_bad_raw = exp_df_bad_raw_grp.get_group((\"parm\",\"qarm\"))\n",
    "# qarm_exp_bad_raw = exp_df_bad_raw_grp.get_group((\"qarm\",\"qarm\"))\n",
    "chr1_exp_bad_raw = exp_df_bad_raw_grp.get_group((\"chr1\",\"chr1\"))\n",
    "\n",
    "\n",
    "pool.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## now to allele1/2 ...\n",
    "\n",
    "all about insertion site and such ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(75, 122)\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "# shape of the inter-arm heatmap ...\n",
    "lo,hi = clr.extent(parm)\n",
    "shape0 = hi-lo\n",
    "lo,hi = clr.extent(qarm)\n",
    "shape1 = hi-lo\n",
    "shape = (shape0,shape1)\n",
    "print(shape)\n",
    "\n",
    "chr1_parm = parm\n",
    "\n",
    "psize = shape0\n",
    "qsize = shape1\n",
    "\n",
    "get_cr = lambda e, shape : (e[shape[0]-1::-1], e[shape[0]-1:])\n",
    "\n",
    "# balanced expecteds ...\n",
    "pqexp = numutils.LazyToeplitz(*get_cr(pqarm_exp_bad[\"balanced.avg\"].values, shape))\n",
    "pexp = numutils.LazyToeplitz(parm_exp_bad[\"balanced.avg\"])\n",
    "# qexp = numutils.LazyToeplitz(qarm_exp_bad[\"balanced.avg\"])\n",
    "chr1exp = numutils.LazyToeplitz(chr1_exp_bad[\"balanced.avg\"])\n",
    "\n",
    "# raw expecteds ...\n",
    "pqexp_raw = numutils.LazyToeplitz(*get_cr(pqarm_exp_bad_raw[\"count.avg\"].values, shape))\n",
    "pexp_raw = numutils.LazyToeplitz(parm_exp_bad_raw[\"count.avg\"])\n",
    "# qexp_raw = numutils.LazyToeplitz(qarm_exp_bad_raw[\"count.avg\"])\n",
    "chr1exp_raw = numutils.LazyToeplitz(chr1_exp_bad_raw[\"count.avg\"])\n",
    "\n",
    "\n",
    "chr1_parm = to_uscs(parm)\n",
    "chr1_qarm = to_uscs(qarm)\n",
    "\n",
    "# some very stupid check:\n",
    "# actually this check breaks at higher resolutions - i.e. small binsize\n",
    "#  because there is a gap between p and q arms - which becomes > 1 bin eventually\n",
    "if (shape0 + shape1) == chr1exp.shape[0]:\n",
    "    print(\n",
    "        np.allclose(np.r_[chr1exp[:shape0,ins_row], chr1exp[-shape1:,ins_row]] , chr1exp[:,ins_row])\n",
    "    )\n",
    "else:\n",
    "    print(f\"make sure at a given binsize {binsize}, centromere is > 1 bin ...\")\n",
    "\n",
    "\n",
    "# the following must be always true, though - as it accounts for the centromere size\n",
    "assumption = np.diff(clr.extent(parm))+np.diff(clr.extent(centro))+np.diff(clr.extent(qarm))-2 == np.diff(clr.extent(chrom))\n",
    "assert assumption"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### let's extract allele1/2-related observed, expected and weights ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "  \n",
    "# WE ARE NOT GOING TO USE THE WEIGHTS FOR THE ALLELE1/2 ITSELF ...\n",
    "# AS IT IS UNCLEAR - WHAT THEY REFLECT - ALLELE1 AND ALLELE2 AREN'T COMPARABLE\n",
    "# THEMSELVES , ONLY HOW THEY INTERACT WITH THE REST OF THE GENOME ...\n",
    "# wa1, = clr.bins().fetch(\"allele1\")[\"weight\"]\n",
    "# wa2, = clr.bins().fetch(\"allele2\")[\"weight\"]\n",
    "                \n",
    "\n",
    "# allele1/2 observed - raw:\n",
    "obs_r_a1_1p, = clr.matrix(balance=False).fetch(\"allele1\",chr1_parm)\n",
    "obs_r_a1_1q, = clr.matrix(balance=False).fetch(\"allele1\",chr1_qarm)\n",
    "\n",
    "obs_r_a2_1p, = clr.matrix(balance=False).fetch(\"allele2\",chr1_parm)\n",
    "obs_r_a2_1q, = clr.matrix(balance=False).fetch(\"allele2\",chr1_qarm)\n",
    "\n",
    "# balancing weights p-arm with bad_bins applied ...\n",
    "wp = clr.bins().fetch(chr1_parm)[weight_name].values\n",
    "lo,hi = clr.extent(chr1_parm)\n",
    "bad_bins_parm = bad_bins[(bad_bins>=lo)&(bad_bins<hi)] - lo\n",
    "if len(bad_bins_parm) > 0:\n",
    "    wp[bad_bins_parm] = np.nan\n",
    "\n",
    "# balancing weights q-arm with bad_bins masking applied ...\n",
    "wq = clr.bins().fetch(chr1_qarm)[weight_name].values\n",
    "lo,hi = clr.extent(chr1_parm)\n",
    "bad_bins_parm = bad_bins[(bad_bins>=lo)&(bad_bins<hi)] - lo\n",
    "if len(bad_bins_parm) > 0:\n",
    "    wp[bad_bins_parm] = np.nan\n",
    "\n",
    "\n",
    "# # allele1/2 observed - balanced:\n",
    "# obs_b_a1_1p = wp * obs_r_a1_1p\n",
    "# obs_b_a1_1q = wp * obs_r_a1_1q\n",
    "\n",
    "# obs_b_a2_1p = wq * obs_r_a2_1p\n",
    "# obs_b_a2_1q = wq * obs_r_a2_1q\n",
    "\n",
    "# p-arm expected balanced al1 and al2 are the same because insertion sites is really close (+/- 1kb):\n",
    "exp_b_a1a2_1p = pexp[:,ins_row].flatten()\n",
    "exp_b_a1a2_1p_chr1 = chr1exp[:psize,ins_row].flatten()\n",
    "# p-arm expected raw al1 and al2 are the same because insertion sites is really close (+/- 1kb):\n",
    "exp_r_a1a2_1p = pexp_raw[:,ins_row].flatten()\n",
    "exp_r_a1a2_1p_chr1 = chr1exp_raw[:psize,ins_row].flatten()\n",
    "\n",
    "# q-arm expected balanced al1 and al2 are the same because insertion sites is really close (+/- 1kb):\n",
    "exp_b_a1a2_1q = pqexp[ins_row,:].flatten()\n",
    "exp_b_a1a2_1q_chr1 = chr1exp[-qsize:,ins_row].flatten()\n",
    "# q-arm expected balanced al1 and al2 are the same because insertion sites is really close (+/- 1kb):\n",
    "exp_r_a1a2_1q = pqexp_raw[ins_row,:].flatten()\n",
    "exp_r_a1a2_1q_chr1 = chr1exp_raw[-qsize:,ins_row].flatten()\n",
    "\n",
    "# if balanced:\n",
    "#     wa1, = clr.bins().fetch(\"allele1\")[\"weight\"]\n",
    "#     wa2, = clr.bins().fetch(\"allele2\")[\"weight\"]\n",
    "#     # print(wa1,wa2)725\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5401e19fd57e4d9d89e1256055df6880",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd53698cd4d248b195146919ddf532ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntRangeSlider(value=(0, 75), continuous_update=False, description='p_range_zoom', max=7…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# visualize compartments:\n",
    "f = plt.figure(figsize=(9,5),constrained_layout=True)\n",
    "sp = gridspec.GridSpec(ncols=4,\n",
    "                       nrows=3,\n",
    "                       height_ratios=[2,1,1],\n",
    "                       width_ratios=[0.3*psize,psize,qsize,0.3*psize],\n",
    "                       figure=f\n",
    "                      )\n",
    "\n",
    "axp = f.add_subplot(sp[0,1])\n",
    "axq = f.add_subplot(sp[0,2],sharey=axp)\n",
    "\n",
    "axpc = f.add_subplot(sp[1,1],sharex=axp)\n",
    "axqc = f.add_subplot(sp[1,2],sharex=axq,sharey=axpc)\n",
    "\n",
    "axprt = f.add_subplot(sp[2,1],sharex=axp)\n",
    "axqrt = f.add_subplot(sp[2,2],sharex=axq,sharey=axprt)\n",
    "\n",
    "\n",
    "axpcb = f.add_subplot(sp[1,0])\n",
    "axqcb = f.add_subplot(sp[1,3])\n",
    "\n",
    "axprtb = f.add_subplot(sp[2,0])\n",
    "axqrtb = f.add_subplot(sp[2,3])\n",
    "\n",
    "\n",
    "axp.tick_params(bottom=False,labelbottom=False)\n",
    "axq.tick_params(bottom=False,labelbottom=False,left=False,labelleft=False)\n",
    "axpc.tick_params(bottom=False,labelbottom=False)\n",
    "axqc.tick_params(bottom=False,labelbottom=False,left=False,labelleft=False)\n",
    "axqrt.tick_params(left=False,labelleft=False)\n",
    "\n",
    "\n",
    "clr = samples[\"cool\"][0]\n",
    "\n",
    "rtdf = binned_rt[\"value_rt\"].reset_index(drop=True).values\n",
    "\n",
    "p_range_zoom=widgets.IntRangeSlider(\n",
    "        value=clr.extent(chr1_parm),\n",
    "        min=0,\n",
    "        max=clr.extent(chr1_parm)[1],\n",
    "        step=1,\n",
    "        continuous_update=False)\n",
    "\n",
    "q_range_zoom=widgets.IntRangeSlider(\n",
    "        value=clr.extent(chr1_qarm),\n",
    "        min=clr.extent(chr1_qarm)[0],\n",
    "        max=clr.extent(chr1_qarm)[1],\n",
    "        step=1,\n",
    "        continuous_update=False)\n",
    "\n",
    "sub_frac = widgets.FloatSlider(\n",
    "        value=0.65,\n",
    "        min=0,\n",
    "        max=1.0,\n",
    "        step=0.05)\n",
    "\n",
    "@widgets.interact(\n",
    "        p_range_zoom = p_range_zoom,\n",
    "        q_range_zoom = q_range_zoom,\n",
    "        log=True,\n",
    "        balanced=True,\n",
    "        OE=False,\n",
    "        samplez = samples[\"sample\"].values,\n",
    "        sub_frac = sub_frac\n",
    ")\n",
    "def update(p_range_zoom,\n",
    "           q_range_zoom,\n",
    "           log,\n",
    "           balanced,\n",
    "           OE,\n",
    "           samplez,\n",
    "           sub_frac\n",
    "          ):\n",
    "    # we are switching samples inside interactively ...\n",
    "    clr, = samples[\"cool\"][samples[\"sample\"] == samplez].values\n",
    "\n",
    "    axp.clear()\n",
    "    axq.clear()\n",
    "    \n",
    "    axpcb.clear()\n",
    "    axqcb.clear()\n",
    "    axprtb.clear()\n",
    "    axqrtb.clear()\n",
    "    \n",
    "    axpc.clear()\n",
    "    axqc.clear()\n",
    "    axprt.clear()\n",
    "    axqrt.clear()\n",
    "    # extract balancing weights for\n",
    "    # alleles 1 and 2 - they are meaningless I guess\n",
    "    # they only reflect - the total # of interactions\n",
    "    # between allele1/2 and chr1\n",
    "\n",
    "    # p-arm data:\n",
    "    d1p = np.random.binomial(obs_r_a1_1p,sub_frac).T\n",
    "    d2p = obs_r_a2_1p\n",
    "    if balanced:\n",
    "        d1p = d1p * wp\n",
    "        d2p = d2p * wp\n",
    "        ep12 = exp_b_a1a2_1p\n",
    "        epc12 = exp_b_a1a2_1p_chr1\n",
    "    else:\n",
    "        ep12 = exp_r_a1a2_1p\n",
    "        epc12 = exp_r_a1a2_1p_chr1\n",
    "    if OE:\n",
    "        # only arm level expected ...\n",
    "        d1p = d1p / ep12\n",
    "        d2p = d2p / ep12\n",
    "    # adjust everything to the visible region:\n",
    "    xp = range(*p_range_zoom)\n",
    "    # compartments:\n",
    "    cmpp = cmp_vals[slice(*p_range_zoom)]\n",
    "    rtpp = rtdf[slice(*p_range_zoom)]\n",
    "\n",
    "    # q-arm data:\n",
    "    d1q = np.random.binomial(obs_r_a1_1q,sub_frac).T\n",
    "    d2q = obs_r_a2_1q\n",
    "    if balanced:\n",
    "        d1q = d1q * wq\n",
    "        d2q = d2q * wq\n",
    "        epq12 = exp_b_a1a2_1q\n",
    "        epqc12 = exp_b_a1a2_1q_chr1\n",
    "    else:\n",
    "        epq12 = exp_r_a1a2_1q\n",
    "        epqc12 = exp_r_a1a2_1q_chr1\n",
    "    if OE:\n",
    "        # only arm level expected ...\n",
    "        d1q = d1q / epq12\n",
    "        d2q = d2q / epq12\n",
    "    # adjust everything to the visible region:\n",
    "    xq = range(*q_range_zoom)\n",
    "    cmpq = cmp_vals[slice(*q_range_zoom)]\n",
    "    rtpq = rtdf[slice(*q_range_zoom)]\n",
    "\n",
    "    axp.plot(xp, d1p[slice(*p_range_zoom)], 'gx', label=\"allele1\", alpha=0.9)\n",
    "    axp.plot(xp, d2p[slice(*p_range_zoom)], 'mx', label=\"allele2\", alpha=0.9)\n",
    "    if not OE:\n",
    "        axp.plot(xp, ep12[slice(*p_range_zoom)], 'g-', alpha=0.5)\n",
    "        axp.plot(xp, epc12[slice(*p_range_zoom)], 'r-', alpha=0.5)\n",
    "    axp.set_xlim(*p_range_zoom)\n",
    "\n",
    "    q_range_zoom_rel = [_-clr.offset(chr1_qarm) for _ in q_range_zoom]\n",
    "    axq.plot(xq, d1q[slice(*q_range_zoom_rel)], 'gx', label=\"allele1\", alpha=0.9)\n",
    "    axq.plot(xq, d2q[slice(*q_range_zoom_rel)], 'mx', label=\"allele2\", alpha=0.9)\n",
    "    if not OE:\n",
    "        axq.plot(xq, epq12[slice(*q_range_zoom_rel)], 'g-', alpha=0.5)\n",
    "        axq.plot(xq, epqc12[slice(*q_range_zoom_rel)], 'r-', alpha=0.5)\n",
    "    axq.set_xlim(*q_range_zoom)\n",
    "    axq.legend(loc=\"best\")\n",
    "\n",
    "    if log:\n",
    "        axp.set_yscale(\"log\")\n",
    "        axq.set_yscale(\"log\")\n",
    "    \n",
    "    fillcolor_compartment_style(cmp_vals, axpc)\n",
    "    fillcolor_compartment_style(cmp_vals, axqc)\n",
    "\n",
    "    fillcolor_compartment_style(rtdf, axprt)\n",
    "    fillcolor_compartment_style(rtdf, axqrt)\n",
    "    \n",
    "    axpcb.bar(range(6),bar_signal(d1p[[slice(*p_range_zoom)]],cmpp)+bar_signal(d2p[[slice(*p_range_zoom)]],cmpp),color=list('rkbrkb'))\n",
    "    axqcb.bar(range(6),bar_signal(d1q[slice(*q_range_zoom_rel)],cmpq)+bar_signal(d2q[slice(*q_range_zoom_rel)],cmpq),color=list('rkbrkb'))\n",
    "\n",
    "    axprtb.bar(range(6),bar_signal(d1p[slice(*p_range_zoom)],rtpp)+bar_signal(d2p[slice(*p_range_zoom)],rtpp),color=list('rkbrkb'))\n",
    "    axqrtb.bar(range(6),bar_signal(d1q[slice(*q_range_zoom_rel)],rtpq)+bar_signal(d2q[slice(*q_range_zoom_rel)],rtpq),color=list('rkbrkb'))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bar_signal??\n",
    "\n",
    "# def bar_signal(oe,signal):\n",
    "#     oe1 = np.nanmean(oe[signal >= 0.1])\n",
    "#     oe2 = np.nanmean(oe[(signal >= -0.1)&(signal < 0.1)])\n",
    "#     oe3 = np.nanmean(oe[signal < -0.1])\n",
    "#     return [oe1,oe2,oe3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01e1d758c34645c188db6865b3d9dae0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd6d7fa5779e49a387aeb5bdc1f7d214",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntRangeSlider(value=(0, 75), continuous_update=False, description='p_range_zoom', max=7…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## # test (1)\n",
    "\n",
    "# difflist_a1 = []\n",
    "# difflist_a2 = []\n",
    "# At = []\n",
    "# Bt = []\n",
    "# num_iters = 10000\n",
    "\n",
    "# for iteration in range(num_iters):\n",
    "#     aa = np.random.permutation( oe_eigen_df_filtered['compartment'].values )\n",
    "#     oe_eigen_df_filtered['randomized_comp'] = pd.Series(aa)\n",
    "#     grp_by_rnd_cmp = oe_eigen_df_filtered.groupby('randomized_comp')\n",
    "#     gt = grp_by_rnd_cmp['allele1','allele2'].mean()\n",
    "#     # first test expected:\n",
    "#     all1_test = gt['allele1']\n",
    "#     all2_test = gt['allele2']\n",
    "#     all1_ABdiff = all1_test['A'] - all1_test['B']\n",
    "#     all2_ABdiff = all2_test['B'] - all2_test['A']\n",
    "#     difflist_a1.append(all1_ABdiff)\n",
    "#     difflist_a2.append(all2_ABdiff)\n",
    "#     # second test expected:\n",
    "#     cmpA_test = gt.loc['A']\n",
    "#     cmpB_test = gt.loc['B']\n",
    "#     Atest = cmpA_test['allele1'] - cmpA_test['allele2']\n",
    "#     Btest = cmpB_test['allele2'] - cmpB_test['allele1']\n",
    "#     At.append(Atest)\n",
    "#     Bt.append(Btest)\n",
    "\n",
    "# # test (2)\n",
    "# # this would be a different test probably ...\n",
    "# # start = 1\n",
    "# # maximum = num_iters # like 10000 or so\n",
    "# # diffAlist = []\n",
    "# # while start <= maximum:\n",
    "# #     aa = oe_eigen_df_filtered['compartment'].reindex(np.random.permutation(oe_eigen_df_filtered['compartment'].index)).reset_index(drop=True)\n",
    "# #     oe_eigen_df_filtered['randomized_comp'] = pd.Series(aa)\n",
    "# #     randa1 = oe_eigen_df_filtered.loc[oe_eigen_df_filtered['randomized_comp'] == 'A', 'allele1'].mean()\n",
    "# #     randa2 = oe_eigen_df_filtered.loc[oe_eigen_df_filtered['randomized_comp'] == 'A', 'allele2'].mean()\n",
    "# #     diffA = randa1 - randa2\n",
    "# #     #print (diffA)\n",
    "# #     diffAlist.append(diffA)\n",
    "# #     start += 1\n",
    "\n",
    "\n",
    "\n",
    "# visualize compartments:\n",
    "fx = plt.figure(figsize=(4,2),constrained_layout=True)\n",
    "spx = gridspec.GridSpec(ncols=2,\n",
    "                       nrows=1,\n",
    "                       width_ratios=[1,1],\n",
    "                       figure=fx\n",
    "                      )\n",
    "\n",
    "axp = fx.add_subplot(spx[0])\n",
    "axq = fx.add_subplot(spx[1])#,sharey=axp)\n",
    "\n",
    "\n",
    "# axp.tick_params(bottom=False,labelbottom=False)\n",
    "# axq.tick_params(bottom=False,labelbottom=False,left=False,labelleft=False)\n",
    "\n",
    "clr = samples[\"cool\"][0]\n",
    "\n",
    "p_range_zoom=widgets.IntRangeSlider(\n",
    "        value=clr.extent(chr1_parm),\n",
    "        min=0,\n",
    "        max=clr.extent(chr1_parm)[1],\n",
    "        step=1,\n",
    "        continuous_update=False)\n",
    "\n",
    "q_range_zoom=widgets.IntRangeSlider(\n",
    "        value=clr.extent(chr1_qarm),\n",
    "        min=clr.extent(chr1_qarm)[0],\n",
    "        max=clr.extent(chr1_qarm)[1],\n",
    "        step=1,\n",
    "        continuous_update=False)\n",
    "\n",
    "sub_frac = widgets.FloatSlider(\n",
    "        value=0.65,\n",
    "        min=0,\n",
    "        max=1.0,\n",
    "        step=0.05)\n",
    "\n",
    "threshold = widgets.FloatSlider(\n",
    "        value=0.1,\n",
    "        min=0,\n",
    "        max=0.5,\n",
    "        step=0.05)\n",
    "\n",
    "@widgets.interact(\n",
    "        p_range_zoom = p_range_zoom,\n",
    "        q_range_zoom = q_range_zoom,\n",
    "        balanced=True,\n",
    "        OE=True,\n",
    "        samplez = samples[\"sample\"].values,\n",
    "        sub_frac = sub_frac,\n",
    "        threshold = threshold,\n",
    ")\n",
    "def update(p_range_zoom,\n",
    "           q_range_zoom,\n",
    "           balanced,\n",
    "           OE,\n",
    "           samplez,\n",
    "           sub_frac,\n",
    "           threshold,\n",
    "          ):\n",
    "    # we are switching samples inside interactively ...\n",
    "    clr, = samples[\"cool\"][samples[\"sample\"] == samplez].values\n",
    "\n",
    "    axp.clear()\n",
    "    axq.clear()\n",
    "    # extract balancing weights for\n",
    "    # alleles 1 and 2 - they are meaningless I guess\n",
    "    # they only reflect - the total # of interactions\n",
    "    # between allele1/2 and chr1\n",
    "    \n",
    "    aa_list_p = []\n",
    "    rnd_list_p = []\n",
    "    aa_list_q = []\n",
    "    rnd_list_q = []\n",
    "    for ii in range(1):\n",
    "        # p-arm data:\n",
    "        d1p = np.random.binomial(obs_r_a1_1p,sub_frac).T\n",
    "        d2p = obs_r_a2_1p\n",
    "        if balanced:\n",
    "            d1p = d1p * wp\n",
    "            d2p = d2p * wp\n",
    "            ep12 = exp_b_a1a2_1p\n",
    "            epc12 = exp_b_a1a2_1p_chr1\n",
    "        else:\n",
    "            ep12 = exp_r_a1a2_1p\n",
    "            epc12 = exp_r_a1a2_1p_chr1\n",
    "        if OE:\n",
    "            # only arm level expected ...\n",
    "            d1p = d1p / ep12\n",
    "            d2p = d2p / ep12\n",
    "        # q-arm data:\n",
    "        d1q = np.random.binomial(obs_r_a1_1q,sub_frac).T\n",
    "        d2q = obs_r_a2_1q\n",
    "        if balanced:\n",
    "            d1q = d1q * wq\n",
    "            d2q = d2q * wq\n",
    "            epq12 = exp_b_a1a2_1q\n",
    "            epqc12 = exp_b_a1a2_1q_chr1\n",
    "        else:\n",
    "            epq12 = exp_r_a1a2_1q\n",
    "            epqc12 = exp_r_a1a2_1q_chr1\n",
    "        if OE:\n",
    "            # only arm level expected ...\n",
    "            d1q = d1q / epq12\n",
    "            d2q = d2q / epq12\n",
    "\n",
    "        # adjust everything to the visible region:\n",
    "        xp = range(*p_range_zoom)\n",
    "        # compartments:\n",
    "        cmpp = cmp_vals[slice(*p_range_zoom)]\n",
    "\n",
    "        # adjust everything to the visible region:\n",
    "        xq = range(*q_range_zoom)\n",
    "        cmpq = cmp_vals[slice(*q_range_zoom)]\n",
    "\n",
    "        aa1 = pd.DataFrame({\"set\": [\"A1\",\"AB1\",\"B1\"], \"OE\": bar_signal(d1p[slice(*p_range_zoom)],cmpp,threshold)})\n",
    "        aa2 = pd.DataFrame({\"set\": [\"A2\",\"AB2\",\"B2\"], \"OE\": bar_signal(d2p[slice(*p_range_zoom)],cmpp,threshold)})\n",
    "        aa_list_p.append(aa1)\n",
    "        aa_list_p.append(aa2)\n",
    "        rnd1 = random_test(d1p[slice(*p_range_zoom)],cmpp,iters=1000,thresh=threshold,cyclic=False)\n",
    "        rnd1[\"set\"] = rnd1[\"set\"] + \"1\"\n",
    "        rnd2 = random_test(d2p[slice(*p_range_zoom)],cmpp,iters=1000,thresh=threshold,cyclic=False)\n",
    "        rnd2[\"set\"] = rnd1[\"set\"] + \"2\"\n",
    "        rnd_list_p.append(rnd1)\n",
    "        rnd_list_p.append(rnd2)\n",
    "\n",
    "        q_range_zoom_rel = [_-clr.offset(chr1_qarm) for _ in q_range_zoom]\n",
    "        aa1 = pd.DataFrame({\"set\": [\"A1\",\"AB1\",\"B1\"], \"OE\": bar_signal(d1q[slice(*q_range_zoom_rel)],cmpq,threshold)})\n",
    "        aa2 = pd.DataFrame({\"set\": [\"A2\",\"AB2\",\"B2\"], \"OE\": bar_signal(d2q[slice(*q_range_zoom_rel)],cmpq,threshold)})\n",
    "        aa_list_q.append(aa1)\n",
    "        aa_list_q.append(aa2)\n",
    "        rnd1 = random_test(d1q[slice(*q_range_zoom_rel)],cmpq,iters=1000,thresh=threshold,cyclic=False)\n",
    "        rnd1[\"set\"] = rnd1[\"set\"] + \"1\"\n",
    "        rnd2 = random_test(d2q[slice(*q_range_zoom_rel)],cmpq,iters=1000,thresh=threshold,cyclic=False)\n",
    "        rnd2[\"set\"] = rnd1[\"set\"] + \"2\"\n",
    "        rnd_list_q.append(rnd1)\n",
    "        rnd_list_q.append(rnd2)\n",
    "\n",
    "        \n",
    "    aaaa = pd.concat(rnd_list_p)\n",
    "    sns.stripplot(x=\"set\", y=\"OE\", data=aaaa, ax = axp, alpha=0.1)\n",
    "    aaaa = pd.concat(aa_list_p)\n",
    "    sns.stripplot(x=\"set\", y=\"OE\", data=aaaa, ax = axp, alpha=0.9,color=\"grey\")\n",
    "\n",
    "    \n",
    "    aaaa = pd.concat(rnd_list_q)\n",
    "    sns.stripplot(x=\"set\", y=\"OE\", data=aaaa, ax = axq, alpha=0.1)\n",
    "    aaaa = pd.concat(aa_list_q)\n",
    "    sns.stripplot(x=\"set\", y=\"OE\", data=aaaa, ax = axq, alpha=0.9,color=\"grey\")\n",
    "\n",
    "    #     axp.plot(x=\"set\", y=\"OE\",data=aaaa,markersize=15,facecolor=\"blue\")#, ax = axp, alpha=0.999)\n",
    " \n",
    "#     axp.bar(range(6),bar_signal(d1p[[slice(*p_range_zoom)]],cmpp)+bar_signal(d2p[[slice(*p_range_zoom)]],cmpp),color=list('rkbrkb'))\n",
    "#     axq.bar(range(6),bar_signal(d1q[slice(*q_range_zoom_rel)],cmpq)+bar_signal(d2q[slice(*q_range_zoom_rel)],cmpq),color=list('rkbrkb'))\n",
    "\n",
    "#     axprtb.bar(range(6),bar_signal(d1p[slice(*p_range_zoom)],rtpp)+bar_signal(d2p[slice(*p_range_zoom)],rtpp),color=list('rkbrkb'))\n",
    "#     axqrtb.bar(range(6),bar_signal(d1q[slice(*q_range_zoom_rel)],rtpq)+bar_signal(d2q[slice(*q_range_zoom_rel)],rtpq),color=list('rkbrkb'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_test(oe,comps,iters=100,thresh=0.1,cyclic=False):\n",
    "    \"\"\"\n",
    "    a function that would generate a distribution of OE-averages\n",
    "    for a number of randomized compartment tracks\n",
    "    \"\"\"\n",
    "    oe1_list = []\n",
    "    oe2_list = []\n",
    "    oe3_list = []\n",
    "    \n",
    "    if cyclic:\n",
    "        for i in range(len(comps)):\n",
    "            # permute compartments with all the maskings etc\n",
    "            comps_rnd = np.roll( comps, shift=i )\n",
    "            oe1 = np.nanmean(oe[comps_rnd >= thresh])\n",
    "            oe2 = np.nanmean(oe[(comps_rnd >= -thresh)&(comps_rnd < thresh)])\n",
    "            oe3 = np.nanmean(oe[comps_rnd < -thresh])\n",
    "            oe1_list.append(oe1)\n",
    "            oe2_list.append(oe2)\n",
    "            oe3_list.append(oe3)\n",
    "    else:\n",
    "        for i in range(iters):\n",
    "            # permute compartments with all the maskings etc\n",
    "            comps_rnd = np.random.permutation( comps )\n",
    "            oe1 = np.nanmean(oe[comps_rnd >= thresh])\n",
    "            oe2 = np.nanmean(oe[(comps_rnd >= -thresh)&(comps_rnd < thresh)])\n",
    "            oe3 = np.nanmean(oe[comps_rnd < -thresh])\n",
    "            oe1_list.append(oe1)\n",
    "            oe2_list.append(oe2)\n",
    "            oe3_list.append(oe3)\n",
    "        \n",
    "    oe1_df = pd.DataFrame({\"OE\":oe1_list})\n",
    "    oe1_df[\"set\"] = \"A\"\n",
    "    oe2_df = pd.DataFrame({\"OE\":oe2_list})\n",
    "    oe2_df[\"set\"] = \"AB\"\n",
    "    oe3_df = pd.DataFrame({\"OE\":oe3_list})\n",
    "    oe3_df[\"set\"] = \"B\"\n",
    "    \n",
    "    return pd.concat([oe1_df,oe2_df,oe3_df])\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "# # test (1)\n",
    "\n",
    "# difflist_a1 = []\n",
    "# difflist_a2 = []\n",
    "# At = []\n",
    "# Bt = []\n",
    "# num_iters = 10000\n",
    "\n",
    "# for iteration in range(num_iters):\n",
    "#     aa = np.random.permutation( oe_eigen_df_filtered['compartment'].values )\n",
    "#     oe_eigen_df_filtered['randomized_comp'] = pd.Series(aa)\n",
    "#     grp_by_rnd_cmp = oe_eigen_df_filtered.groupby('randomized_comp')\n",
    "#     gt = grp_by_rnd_cmp['allele1','allele2'].mean()\n",
    "#     # first test expected:\n",
    "#     all1_test = gt['allele1']\n",
    "#     all2_test = gt['allele2']\n",
    "#     all1_ABdiff = all1_test['A'] - all1_test['B']\n",
    "#     all2_ABdiff = all2_test['B'] - all2_test['A']\n",
    "#     difflist_a1.append(all1_ABdiff)\n",
    "#     difflist_a2.append(all2_ABdiff)\n",
    "#     # second test expected:\n",
    "#     cmpA_test = gt.loc['A']\n",
    "#     cmpB_test = gt.loc['B']\n",
    "#     Atest = cmpA_test['allele1'] - cmpA_test['allele2']\n",
    "#     Btest = cmpB_test['allele2'] - cmpB_test['allele1']\n",
    "#     At.append(Atest)\n",
    "#     Bt.append(Btest)\n",
    "\n",
    "# # test (2)\n",
    "# # this would be a different test probably ...\n",
    "# # start = 1\n",
    "# # maximum = num_iters # like 10000 or so\n",
    "\n",
    "# # diffAlist = []\n",
    "# # while start <= maximum:\n",
    "# #     aa = oe_eigen_df_filtered['compartment'].reindex(np.random.permutation(oe_eigen_df_filtered['compartment'].index)).reset_index(drop=True)\n",
    "# #     oe_eigen_df_filtered['randomized_comp'] = pd.Series(aa)\n",
    "# #     randa1 = oe_eigen_df_filtered.loc[oe_eigen_df_filtered['randomized_comp'] == 'A', 'allele1'].mean()\n",
    "# #     randa2 = oe_eigen_df_filtered.loc[oe_eigen_df_filtered['randomized_comp'] == 'A', 'allele2'].mean()\n",
    "# #     diffA = randa1 - randa2\n",
    "# #     #print (diffA)\n",
    "# #     diffAlist.append(diffA)\n",
    "# #     start += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6f41acb4fa84cd3bd86c5c3b14f5054",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d20c61af76b4b99a22e20a67c4a8c09",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntRangeSlider(value=(0, 150), continuous_update=False, description='p_range_zoom', max=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# visualize compartments:\n",
    "f1 = plt.figure(figsize=(9,4),constrained_layout=True)\n",
    "sp1 = gridspec.GridSpec(ncols=1, nrows=2, height_ratios=[2,1], figure=f1)\n",
    "\n",
    "axp1 = f1.add_subplot(sp1[0,0])\n",
    "\n",
    "axpc1 = f1.add_subplot(sp1[1,0],sharex=axp1)\n",
    "\n",
    "\n",
    "clr = samples[\"cool\"][0]\n",
    "\n",
    "chr1_parm = \"chr1:0-74626886\"\n",
    "\n",
    "# chr1_qarm = \"chr1:74626887-196202544\"\n",
    "\n",
    "p_range_zoom=widgets.IntRangeSlider(\n",
    "        value=clr.extent(chr1_parm),\n",
    "        min=0,\n",
    "        max=clr.extent(chr1_parm)[1],\n",
    "        step=1,\n",
    "        continuous_update=False)\n",
    "\n",
    "\n",
    "@widgets.interact(#chrom=clr.chromnames,\n",
    "        p_range_zoom = p_range_zoom,\n",
    "        log=True,\n",
    "        balanced=True,\n",
    "        samplez = samples[\"sample\"].values,\n",
    ")\n",
    "def update(p_range_zoom,log,balanced,samplez):\n",
    "    clr, = samples[\"cool\"][samples[\"sample\"] == samplez].values\n",
    "\n",
    "    axp1.clear()\n",
    "    axpc1.clear()\n",
    "    \n",
    "    # extract balacing weights for\n",
    "    # alleles 1 and 2 - they are meaningless I guess\n",
    "    # they only reflect - the total # of interactions\n",
    "    # between allele1/2 and chr1\n",
    "    \n",
    "    if balanced:\n",
    "        w1, = clr.bins().fetch(\"allele1\")[\"weight\"]\n",
    "        w2, = clr.bins().fetch(\"allele2\")[\"weight\"]\n",
    "        # print(w1,w2)\n",
    "            \n",
    "    # p-arm data:\n",
    "    # obs:\n",
    "    d1p, = clr.matrix(balance=balanced).fetch(\"allele1\",chr1_parm)\n",
    "    d2p, = clr.matrix(balance=balanced).fetch(\"allele2\",chr1_parm)\n",
    "    if balanced:\n",
    "        d1p /= w1\n",
    "        d2p /= w2\n",
    "    if log:\n",
    "        d1p = np.log(d1p)\n",
    "        d2p = np.log(d2p)+0.2\n",
    "    xp = range(*p_range_zoom)\n",
    "    # compartments:\n",
    "    cmpp = cmp_vals[slice(*p_range_zoom)]\n",
    "    \n",
    "    axp1.plot(xp, d1p[slice(*p_range_zoom)], 'gx', label=\"allele1\", alpha=0.9)\n",
    "    axp1.plot(xp, d2p[slice(*p_range_zoom)], 'mx', label=\"allele2\", alpha=0.9)\n",
    "    axp1.set_xlim(*p_range_zoom)\n",
    "    axp1.legend(loc=\"best\")\n",
    "    \n",
    "    fillcolor_compartment_style(cmp_vals, axpc1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/venevs/miniconda3/envs/newexp/lib/python3.7/site-packages/ipykernel_launcher.py:2: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f21ec2825cb4923b22944031c266b1d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "77f9c1bbb5a14c5ab6a03389658a4353",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntRangeSlider(value=(0, 75), continuous_update=False, description='p_range_zoom', max=7…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# visualize compartments:\n",
    "fc11 = plt.figure(figsize=(9,4),constrained_layout=True)\n",
    "sp111 = gridspec.GridSpec(ncols=2, nrows=2,width_ratios=[4,1], height_ratios=[2,1], figure=fc11)\n",
    "\n",
    "\n",
    "axp1 = fc11.add_subplot(sp111[0,0])\n",
    "\n",
    "axpc1 = fc11.add_subplot(sp111[1,0],sharex=axp1)\n",
    "\n",
    "\n",
    "axscat = fc11.add_subplot(sp111[0,1],sharey=axp1)\n",
    "axbar = fc11.add_subplot(sp111[1,1])\n",
    "\n",
    "\n",
    "clr = samples[\"cool\"][0]\n",
    "\n",
    "chr1_parm = \"chr1:0-74626886\"\n",
    "# chr1_qarm = \"chr1:74626887-196202544\"\n",
    "\n",
    "p_range_zoom=widgets.IntRangeSlider(\n",
    "        value=clr.extent(chr1_parm),\n",
    "        min=0,\n",
    "        max=clr.extent(chr1_parm)[1],\n",
    "        step=1,\n",
    "        continuous_update=False)\n",
    "\n",
    "\n",
    "sub_frac = widgets.FloatSlider(\n",
    "        value=0.65,\n",
    "        min=0,\n",
    "        max=1.0,\n",
    "        step=0.05)\n",
    "\n",
    "\n",
    "@widgets.interact(#chrom=clr.chromnames,\n",
    "        p_range_zoom = p_range_zoom,\n",
    "        log=True,\n",
    "        balanced=True,\n",
    "        sub_frac = sub_frac,\n",
    "        samplez = samples[\"sample\"].values,\n",
    ")\n",
    "def update(p_range_zoom,log,balanced,sub_frac,samplez):\n",
    "    clr, = samples[\"cool\"][samples[\"sample\"] == samplez].values\n",
    "\n",
    "    axp1.clear()\n",
    "    axpc1.clear()\n",
    "    axscat.clear()\n",
    "    axbar.clear()\n",
    "    \n",
    "    # extract balacing weights for\n",
    "    # alleles 1 and 2 - they are meaningless I guess\n",
    "    # they only reflect - the total # of interactions\n",
    "    # between allele1/2 and chr1\n",
    "    \n",
    "    if balanced:\n",
    "        w1, = clr.bins().fetch(\"allele1\")[\"weight\"]\n",
    "        w2, = clr.bins().fetch(\"allele2\")[\"weight\"]\n",
    "        # print(w1,w2)\n",
    "            \n",
    "    # p-arm data:\n",
    "    # obs:\n",
    "    d1p, = clr.matrix(balance=False).fetch(\"allele1\",chr1_parm)\n",
    "    d1p = np.random.binomial(d1p,sub_frac).T\n",
    "    if balanced:\n",
    "        d1p = d1p * clr.bins().fetch(chr1_parm)[weight_name].values * w1\n",
    "\n",
    "    d2p, = clr.matrix(balance=balanced).fetch(\"allele2\",chr1_parm)\n",
    "    # exp:\n",
    "    ep1, = pexp[:,ins_row].T\n",
    "    ep2, = pexp[:,ins_row].T\n",
    "    #     ep1, = pexp[:,725].T\n",
    "    #     ep2, = pexp[:,725].T\n",
    "    \n",
    "    if balanced:\n",
    "        #         d1p /= w1\n",
    "        #         d2p /= w2\n",
    "        #         ep1 /= w1\n",
    "        #         ep2 /= w2\n",
    "        # Obs/Exp :\n",
    "        d1p = np.divide(d1p,ep1)\n",
    "        d2p = np.divide(d2p,ep2)\n",
    "        oe1p = d1p.copy()\n",
    "        oe2p = d2p.copy()\n",
    "    if log:\n",
    "        d1p = np.log(d1p)\n",
    "        d2p = np.log(d2p)#+0.2\n",
    "\n",
    "    a1_vis = d1p[slice(*p_range_zoom)]\n",
    "    a2_vis = d2p[slice(*p_range_zoom)]\n",
    "    oe1_vis = oe1p[slice(*p_range_zoom)]\n",
    "    oe2_vis = oe2p[slice(*p_range_zoom)]\n",
    "    xp = range(*p_range_zoom)\n",
    "    \n",
    "    axp1.bar(xp, a1_vis, label=\"allele1\", alpha=0.6)#, 'gx-', label=\"allele1\", alpha=0.9)\n",
    "    axp1.bar(xp, a2_vis, label=\"allele2\", alpha=0.3)#, 'mx-', label=\"allele2\", alpha=0.9)\n",
    "    axp1.set_xlim(*p_range_zoom)\n",
    "    axp1.legend(loc=\"best\")\n",
    "    \n",
    "    axscat.scatter(a1_vis,a2_vis,alpha=0.4)\n",
    "    \n",
    "    # compartments:\n",
    "    cmpp = cmp_vals[slice(*p_range_zoom)]\n",
    "    fillcolor_compartment_style(cmp_vals, axpc1, bin_range=p_range_zoom)\n",
    "    axpc1.set_xlim(*p_range_zoom)\n",
    "    \n",
    "    \n",
    "    #     [a1A,a2A,a1B,a2B]\n",
    "    # ...\n",
    "    a1A = np.nanmean(oe1_vis[cmpp >= 0.1])\n",
    "    a1AB = np.nanmean(oe1_vis[(cmpp >= -0.1)&(cmpp < 0.1)])\n",
    "    a1B = np.nanmean(oe1_vis[cmpp < -0.1])\n",
    "\n",
    "    a2A = np.nanmean(oe2_vis[cmpp >= 0.1])\n",
    "    a2AB = np.nanmean(oe2_vis[(cmpp >= -0.1)&(cmpp < 0.1)])\n",
    "    a2B = np.nanmean(oe2_vis[cmpp < -0.1])\n",
    "\n",
    "    axbar.bar(range(6),[a1A,a1AB,a1B,a2A,a2AB,a2B],color=list('rrrggg'))\n",
    "#     print([a1A,a2A,a1B,a2B])\n",
    "#     matplotlib.pyplot.bar(x, height, width=0.8, bottom=None, *, align='center', data=None, **kwargs)[source]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frg = plt.figure(figsize=(3,3))\n",
    "plt.hist(cmp_vals,bins=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.bar?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bar_AB(ev,ar1,ar2):\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## why A-B bar plots might be misleading:\n",
    "\n",
    "1. definition of compartments might be impresize - i.e. a dip in A, might actually be a small B-compartment\n",
    "2. when comparing Obs/Exp for allele1 and allele2 - we might be off because allele2 is shifted up overall - why is that is a separate question ...\n",
    "\n",
    "so it seems like the best thing we could do now is to carefully look at the Obs for both and see if they are \"in-phase\" or in \"opposite phases\" with each other ...\n",
    "\n",
    "... and if that observation is consistent across samples ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### we'll do them anyways !!!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add compartment status info\n",
    "conditions = [\n",
    "    (oe_eigen_df['E1'] >= -0),\n",
    "    (oe_eigen_df['E1'] < -0)]\n",
    "\n",
    "choices = ['A', 'B']\n",
    "oe_eigen_df['compartment'] = np.select(conditions, choices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.binomial([1,2,3,4,5,6,7,8,9],0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DO NOT LOOK BELOW - INCOMPREHENSIBLE DOWN THERE ...\n",
    "\n",
    "there is a little mess down below ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RE-READ SOME COOLERS AT LOWER RESOLUTION 1MB TO DO SOME QUICK CALCULATIONS ...\n",
    "binsize = 1_000_000\n",
    "res_human = f\"{int(binsize/1000)}kb\"\n",
    "\n",
    "cool_path = \"/home/venevs/DOTS_TESTING/alv-chicken/oldref-20200410\"\n",
    "get_cpath = lambda c: os.path.join(cool_path,c+f\"::/resolutions/{binsize}\")\n",
    "\n",
    "samples[\"cool\"] = [cooler.Cooler(get_cpath(c)) for c in samples[\"mcool\"]]\n",
    "\n",
    "\n",
    "samples[\"sum\"] = [s.info[\"sum\"] for s in samples[\"cool\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trans interactions (whole chromosome ...)\n",
    "f,ax = plt.subplots()\n",
    "\n",
    "\n",
    "for i in range(2,10):\n",
    "    c = samples[\"cool\"][i]\n",
    "    balance = False\n",
    "    cname = \"balanced\" if balance else \"count\"\n",
    "    hh = c.matrix(balance=balance,as_pixels=True,sparse=True)\n",
    "    x = []\n",
    "    y = []\n",
    "    for _c0,_c2 in itertools.combinations(c.chromnames[:-3],2):\n",
    "        _x = float(c.chromsizes[_c0])*c.chromsizes[_c2]\n",
    "        _y = hh.fetch(_c0,_c2)[cname].sum()#/c.info[\"sum\"]\n",
    "        x.append(_x)\n",
    "        y.append(_y)\n",
    "    ax.plot(x,y,\"o-\",alpha=0.7,label=f\"{samples['sample'][i]}\")\n",
    "\n",
    "\n",
    "ax.legend(loc=\"best\")\n",
    "ax.set_xlabel(\"inter chromosomal area, bp^2\")\n",
    "ax.set_ylabel(\"# of interactions\")\n",
    "ax.set_title(\"trans interactions, chromosome level\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cis interactions - whole chromosome ...\n",
    "# trans interactions (whole chromosome ...)\n",
    "f,ax = plt.subplots(figsize=(9,5))\n",
    "\n",
    "\n",
    "for i in range(3,10):\n",
    "    c = samples[\"cool\"][i]\n",
    "    balance = True\n",
    "    cname = \"balanced\" if balance else \"count\"\n",
    "    hh = c.matrix(balance=balance,as_pixels=True,sparse=True)\n",
    "    x = []\n",
    "    y = []\n",
    "    for chrom in c.chromnames[:-3]:\n",
    "        _x = float(c.chromsizes[chrom])\n",
    "        _y = np.nansum(hh.fetch(chrom)[cname])#/c.info[\"sum\"]\n",
    "        x.append(_x)\n",
    "        y.append(_y)\n",
    "    ax.plot(x,y,\"o-\",label=f\"{samples['sample'][i]}\")\n",
    "    \n",
    "    \n",
    "ax.legend(loc=\"best\",frameon=False)\n",
    "ax.set_xlabel(\"chrom size, bp\")\n",
    "ax.set_ylabel(\"# of interactions\")\n",
    "ax.set_title(\"cis interactions, chromosome level\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cis_sum = []\n",
    "for c in samples[\"cool\"]:\n",
    "    b = c.bins()[:]\n",
    "    p = c.pixels()[:]\n",
    "    cis_mask = b[\"chrom\"][p[\"bin1_id\"].values].values == b[\"chrom\"][p[\"bin2_id\"].values].values\n",
    "    s = p[cis_mask][\"count\"].sum()\n",
    "    cis_sum.append(s)\n",
    "\n",
    "samples[\"cis\"] = cis_sum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## samples stats ... overall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_a12_stats(clr):\n",
    "    sp_a1 = clr.matrix(balance=False).fetch(\"allele1\").sum()\n",
    "    sp_a2 = clr.matrix(balance=False).fetch(\"allele2\").sum()\n",
    "    c1p_a1 = clr.matrix(balance=False).fetch(\"allele1\",\"chr1\").sum()\n",
    "    c1p_a2 = clr.matrix(balance=False).fetch(\"allele2\",\"chr1\").sum()\n",
    "    tp_a1 = clr.matrix(balance=False)[clr.offset(\"allele1\"),:].sum()\n",
    "    tp_a2 = clr.matrix(balance=False)[clr.offset(\"allele2\"),:].sum()\n",
    "    mmm = clr.matrix(balance=False)[clr.offset(\"chrM\"),:].sum()\n",
    "    self_mmm = clr.matrix(balance=False).fetch(\"chrM\",\"chrM\").sum()\n",
    "    #\n",
    "    ret_dict = {\n",
    "        \"self1\":sp_a1,\n",
    "        \"self2\":sp_a2,\n",
    "        \"chr1-a1\":c1p_a1,\n",
    "        \"chr1-a2\":c1p_a2,\n",
    "        \"trans-a1\":tp_a1 - sp_a1 - c1p_a1,\n",
    "        \"trans-a2\":tp_a2 - sp_a2 - c1p_a2,\n",
    "        \"chrM\":mmm-self_mmm,\n",
    "    }\n",
    "    return pd.Series(ret_dict)\n",
    "\n",
    "\n",
    "\n",
    "samples_allele = pd.merge(\n",
    "                    samples,\n",
    "                    samples[~samples[\"sample\"].str.contains(\"WT\")][\"cool\"].apply(get_a12_stats),\n",
    "                    how=\"outer\",\n",
    "                    left_index=True,\n",
    "                    right_index=True,\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples_allele"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fsc = plt.figure(figsize=(7,7))\n",
    "axsc = fsc.add_subplot()\n",
    "\n",
    "cols = [\"self1\",\n",
    "\"self2\",\n",
    "\"chr1-a1\",\n",
    "\"chr1-a2\",\n",
    "\"trans-a1\",\n",
    "\"trans-a2\"]\n",
    "\n",
    "pd.plotting.scatter_matrix(samples_allele[cols].iloc[2:],ax=axsc,marker=\"s\")#,marker_size=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f,ax = plt.subplots(figsize=(9,5),constrained_layout=True)\n",
    "\n",
    "cols = [\"self1\",\n",
    "\"self2\",\n",
    "\"chr1-a1\",\n",
    "\"chr1-a2\",\n",
    "\"trans-a1\",\n",
    "\"trans-a2\",\n",
    "\"chrM\"]\n",
    "\n",
    "txt_feature = widgets.Text(\n",
    "    value=','.join([\"sum\",\"cis\"]+cols),\n",
    "    description='Features:',\n",
    "    disabled=False\n",
    ")\n",
    "\n",
    "\n",
    "@widgets.interact(log=True,features=txt_feature)\n",
    "def update(log,features):\n",
    "    ax.clear()\n",
    "    feats_to_show = features.split(',')\n",
    "    samples_allele.plot(x=\"sample\",y=feats_to_show,kind=\"bar\",ax=ax,logy=log)\n",
    "    \n",
    "    \n",
    "print(\"choose features:\"+','.join([\"sum\",\"cis\"]+cols))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !curl https://hgdownload.soe.ucsc.edu/goldenPath/galGal5/database/cytoBandIdeo.txt.gz | gunzip\n",
    "\n",
    "# mat = samples[\"cool\"][1].matrix().fetch(\"chr1:0-74626886\",\"chr1:0-74626886\")\n",
    "# plt.imshow(np.log(mat),cmap=\"YlOrBr\",vmin=-12,vmax=-1)\n",
    "\n",
    "chr1_parm = \"chr1:0-74626886\"\n",
    "\n",
    "mat = samples[\"cool\"][0].matrix().fetch(chr1_parm,chr1_parm)\n",
    "plt.imshow(np.log(mat),cmap=\"YlOrBr\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mat = samples[\"cool\"][0].matrix().fetch(\"chr1:9000000-10000000\",chr1_parm)\n",
    "plt.imshow(np.log(mat),cmap=\"YlOrBr\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import higlass\n",
    "# import higlass.tilesets\n",
    "# from higlass.client import Track, View"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "host=\"vangogh.ad.umassmed.edu\"\n",
    "some_port = \"12347\"\n",
    "allip = \"0.0.0.0\"\n",
    "server = f\"http://{host}:{some_port}/api/v1/\"\n",
    "hw,hh = 6,300\n",
    "\n",
    "nrows = 2\n",
    "ncols = 2\n",
    "\n",
    "tss = []\n",
    "trs = []\n",
    "views = []\n",
    "\n",
    "for idx,i in enumerate([6,7,8,9]):\n",
    "    ts = higlass.tilesets.cooler(get_cpath(samples[\"mcool\"][i]).split(\"::\")[0])\n",
    "    tr = Track('heatmap', position='center',width=hw,height=hh, tileset=ts, server=server,options={\"name\":samples[\"sample\"][i]})\n",
    "    row = idx%ncols\n",
    "    col = idx%nrows\n",
    "    x = row*hw\n",
    "    y = col*hh\n",
    "    view = View([tr,],x=x,y=y,width=hw, initialXDomain=[0,70_000_000],initialYDomain=[0,70_000_000])\n",
    "    views.append(view)\n",
    "\n",
    "display, server, viewconf = higlass.display(views,location_syncs=[views,],zoom_syncs=[views,], host=allip, server_port=some_port)\n",
    "display"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
